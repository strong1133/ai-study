{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95263864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Unfortunately, I'm a large language model, I don't have the ability to know your personal identity or secrets. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations.\\n\\nIf you're feeling uncertain about who you are or want to explore some questions about yourself, here are a few prompts that might be helpful:\\n\\n* What do you value most in life?\\n* What are your goals and aspirations?\\n* What makes you feel fulfilled and happy?\\n* What are your strengths and weaknesses?\\n\\nFeel free to answer any or all of these questions, and I'll do my best to provide some insights or suggestions.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-22T07:46:54.289054Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5103318833, 'load_duration': 2489081083, 'prompt_eval_count': 28, 'prompt_eval_duration': 350593291, 'eval_count': 133, 'eval_duration': 1596569414, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b4506-72cc-7ee1-9a8c-52609eeb5375-0', usage_metadata={'input_tokens': 28, 'output_tokens': 133, 'total_tokens': 161})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "\n",
    "llm.invoke(\"who am i\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a61a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the capital of the {country}? Return the name of city only\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"country\": \"korea\"})\n",
    "ai_message =  llm.invoke(prompt)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "answer = output_parser.invoke(llm.invoke(prompt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5976dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Seoul' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-22T07:46:54.42583Z', 'done': True, 'done_reason': 'stop', 'total_duration': 123468875, 'load_duration': 61761292, 'prompt_eval_count': 40, 'prompt_eval_duration': 21469084, 'eval_count': 3, 'eval_duration': 24807126, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'} id='lc_run--019b4506-86dd-7f72-b82d-f45c55ff2779-0' usage_metadata={'input_tokens': 40, 'output_tokens': 3, 'total_tokens': 43}\n"
     ]
    }
   ],
   "source": [
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da59034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seoul.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e484f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from locale import currency\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CountryDetail(BaseModel):\n",
    "    capital: str = Field(description=\"The capital of the country\")\n",
    "    population: int = Field(description=\"The  population the country\")\n",
    "    language: str = Field(description=\"The language of the country\")\n",
    "    currency: str = Field(description=\"The currency of the country\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(CountryDetail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9808c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "country_detail_propmt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}:\n",
    "    - Capit\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    \n",
    "    return it in JSON format. and return the JSON dictionary only\n",
    "    \"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "json_ai_message = structured_llm.invoke(country_detail_propmt.invoke({\"country\": \"korea\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db2829b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Seoul', population=51, language='Korean', currency='South Korean won')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(json_ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab6f6479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Seoul',\n",
       " 'population': 51,\n",
       " 'language': 'Korean',\n",
       " 'currency': 'South Korean won'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_ai_message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b7129c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitail_chain = prompt_template | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e693a389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitail_chain.invoke({\"country\": \"korea\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b65ab23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_propmt = PromptTemplate(\n",
    "    template=\"\"\"Guess the name of the country based on the following information:\n",
    "    {information}\n",
    "    Retrun the name of the country only\n",
    "    \"\"\",\n",
    "    input_variables=[\"information\"]\n",
    ")\n",
    "country_chain = country_propmt | llm | output_parser\n",
    "country_chain.invoke({\"information\": \"This country is vert famous for its pasta\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e056626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# final_chain = {\"country\":country_chain} | capitail_chain\n",
    "# final_chain.invoke({\"information\": \"This country is vert famous for its pasta\"}) \n",
    "final_chain = {\"information\": RunnablePassthrough()}|{\"country\":country_chain} | capitail_chain\n",
    "final_chain.invoke( \"This country is vert famous for its pasta\") \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
